{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"1\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s (%(levelname)s): %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import string\n",
    "import ast\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from gemnet.model.gemnet import GemNet\n",
    "from gemnet.training.trainer import Trainer\n",
    "from gemnet.training.metrics import Metrics, BestMetrics\n",
    "from gemnet.training.data_container import DataContainer\n",
    "from gemnet.training.data_provider import DataProvider\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)\n",
    "    \n",
    "# For strings that yaml doesn't parse (e.g. None)\n",
    "for key, val in config.items():\n",
    "    if type(val) is str:\n",
    "        try:\n",
    "            config[key] = ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spherical = config[\"num_spherical\"]\n",
    "num_radial = config[\"num_radial\"]\n",
    "num_blocks = config[\"num_blocks\"]\n",
    "emb_size_atom = config[\"emb_size_atom\"]\n",
    "emb_size_edge = config[\"emb_size_edge\"]\n",
    "emb_size_trip = config[\"emb_size_trip\"]\n",
    "emb_size_quad = config[\"emb_size_quad\"]\n",
    "emb_size_rbf = config[\"emb_size_rbf\"]\n",
    "emb_size_cbf = config[\"emb_size_cbf\"]\n",
    "emb_size_sbf = config[\"emb_size_sbf\"]\n",
    "num_before_skip = config[\"num_before_skip\"]\n",
    "num_after_skip = config[\"num_after_skip\"]\n",
    "num_concat = config[\"num_concat\"]\n",
    "num_atom = config[\"num_atom\"]\n",
    "emb_size_bil_quad = config[\"emb_size_bil_quad\"]\n",
    "emb_size_bil_trip = config[\"emb_size_bil_trip\"]\n",
    "triplets_only = config[\"triplets_only\"]\n",
    "forces_coupled = config[\"forces_coupled\"]\n",
    "direct_forces = config[\"direct_forces\"]\n",
    "mve = config[\"mve\"]\n",
    "cutoff = config[\"cutoff\"]\n",
    "int_cutoff = config[\"int_cutoff\"]\n",
    "envelope_exponent = config[\"envelope_exponent\"]\n",
    "extensive = config[\"extensive\"]\n",
    "output_init = config[\"output_init\"]\n",
    "scale_file = config[\"scale_file\"]\n",
    "data_seed = config[\"data_seed\"]\n",
    "dataset = config[\"dataset\"]\n",
    "val_dataset = config[\"val_dataset\"]\n",
    "num_train = config[\"num_train\"]\n",
    "num_val = config[\"num_val\"]\n",
    "logdir = config[\"logdir\"]\n",
    "loss = config[\"loss\"]\n",
    "tfseed = config[\"tfseed\"]\n",
    "num_steps = config[\"num_steps\"]\n",
    "rho_force = config[\"rho_force\"]\n",
    "ema_decay = config[\"ema_decay\"]\n",
    "weight_decay = config[\"weight_decay\"]\n",
    "grad_clip_max = config[\"grad_clip_max\"]\n",
    "agc = config[\"agc\"]\n",
    "decay_patience = config[\"decay_patience\"]\n",
    "decay_factor = config[\"decay_factor\"]\n",
    "decay_cooldown = config[\"decay_cooldown\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "evaluation_interval = config[\"evaluation_interval\"]\n",
    "patience = config[\"patience\"]\n",
    "save_interval = config[\"save_interval\"]\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "warmup_steps = config[\"warmup_steps\"]\n",
    "decay_steps = config[\"decay_steps\"]\n",
    "decay_rate = config[\"decay_rate\"]\n",
    "staircase = config[\"staircase\"]\n",
    "restart = config[\"restart\"]\n",
    "comment = config[\"comment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(tfseed)\n",
    "\n",
    "logging.info(\"Start training\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "cuda_available = torch.cuda.is_available()\n",
    "logging.info(f\"Available GPUs: {num_gpus}\")\n",
    "logging.info(f\"CUDA Available: {cuda_available}\")\n",
    "if num_gpus == 0:\n",
    "    logging.warning(\"No GPUs were found. Training is run on CPU!\")\n",
    "if not cuda_available:\n",
    "    logging.warning(\"CUDA unavailable. Training is run on CPU!\")\n",
    "\n",
    "# Used for creating a \"unique\" id for a run (almost impossible to generate the same twice)\n",
    "def id_generator(\n",
    "    size=6, chars=string.ascii_uppercase + string.ascii_lowercase + string.digits\n",
    "):\n",
    "    return \"\".join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "# A unique directory name is created for this run based on the input\n",
    "if (restart is None) or (restart == \"None\"):\n",
    "    directory = (\n",
    "        logdir\n",
    "        + \"/\"\n",
    "        + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        + \"_\"\n",
    "        + id_generator()\n",
    "        + \"_\"\n",
    "        + os.path.basename(dataset)\n",
    "        + \"_\"\n",
    "        + str(comment)\n",
    "    )\n",
    "else:\n",
    "    directory = restart\n",
    "\n",
    "logging.info(f\"Directory: {directory}\")\n",
    "logging.info(\"Create directories\")\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "best_dir = os.path.join(directory, \"best\")\n",
    "if not os.path.exists(best_dir):\n",
    "    os.makedirs(best_dir)\n",
    "log_dir = os.path.join(directory, \"logs\")\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "extension = \".pth\"\n",
    "log_path_model = f\"{log_dir}/model{extension}\"\n",
    "log_path_training = f\"{log_dir}/training{extension}\"\n",
    "best_path_model = f\"{best_dir}/model{extension}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Initialize model\")\n",
    "model = GemNet(\n",
    "    num_spherical=num_spherical,\n",
    "    num_radial=num_radial,\n",
    "    num_blocks=num_blocks,\n",
    "    emb_size_atom=emb_size_atom,\n",
    "    emb_size_edge=emb_size_edge,\n",
    "    emb_size_trip=emb_size_trip,\n",
    "    emb_size_quad=emb_size_quad,\n",
    "    emb_size_rbf=emb_size_rbf,\n",
    "    emb_size_cbf=emb_size_cbf,\n",
    "    emb_size_sbf=emb_size_sbf,\n",
    "    num_before_skip=num_before_skip,\n",
    "    num_after_skip=num_after_skip,\n",
    "    num_concat=num_concat,\n",
    "    num_atom=num_atom,\n",
    "    emb_size_bil_quad=emb_size_bil_quad,\n",
    "    emb_size_bil_trip=emb_size_bil_trip,\n",
    "    num_targets=2 if mve else 1,\n",
    "    triplets_only=triplets_only,\n",
    "    direct_forces=direct_forces,\n",
    "    forces_coupled=forces_coupled,\n",
    "    cutoff=cutoff,\n",
    "    int_cutoff=int_cutoff,\n",
    "    envelope_exponent=envelope_exponent,\n",
    "    activation=\"swish\",\n",
    "    extensive=extensive,\n",
    "    output_init=output_init,\n",
    "    scale_file=scale_file,\n",
    ")\n",
    "# push to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "validation = {}\n",
    "\n",
    "logging.info(\"Load dataset\")\n",
    "data_container = DataContainer(\n",
    "    dataset, cutoff=cutoff, int_cutoff=int_cutoff, triplets_only=triplets_only\n",
    ")\n",
    "\n",
    "if val_dataset is not None:\n",
    "    # Initialize DataProvider\n",
    "    if num_train == 0:\n",
    "        num_train = len(data_container)\n",
    "    logging.info(f\"Training data size: {num_train}\")\n",
    "    data_provider = DataProvider(\n",
    "        data_container,\n",
    "        num_train,\n",
    "        0,\n",
    "        batch_size,\n",
    "        seed=data_seed,\n",
    "        shuffle=True,\n",
    "        random_split=True,\n",
    "    )\n",
    "\n",
    "    # Initialize validation datasets\n",
    "    val_data_container = DataContainer(\n",
    "        val_dataset,\n",
    "        cutoff=cutoff,\n",
    "        int_cutoff=int_cutoff,\n",
    "        triplets_only=triplets_only,\n",
    "    )\n",
    "    if num_val == 0:\n",
    "        num_val = len(val_data_container)\n",
    "    logging.info(f\"Validation data size: {num_val}\")\n",
    "    val_data_provider = DataProvider(\n",
    "        val_data_container,\n",
    "        0,\n",
    "        num_val,\n",
    "        batch_size,\n",
    "        seed=data_seed,\n",
    "        shuffle=True,\n",
    "        random_split=True,\n",
    "    )\n",
    "else:\n",
    "    # Initialize DataProvider (splits dataset into 3 sets based on data_seed and provides tf.datasets)\n",
    "    logging.info(f\"Training data size: {num_train}\")\n",
    "    logging.info(f\"Validation data size: {num_val}\")\n",
    "    assert num_train > 0\n",
    "    assert num_val > 0\n",
    "    data_provider = DataProvider(\n",
    "        data_container,\n",
    "        num_train,\n",
    "        num_val,\n",
    "        batch_size,\n",
    "        seed=data_seed,\n",
    "        shuffle=True,\n",
    "        random_split=True,\n",
    "    )\n",
    "    val_data_provider = data_provider\n",
    "\n",
    "# Initialize datasets\n",
    "train[\"dataset_iter\"] = data_provider.get_dataset(\"train\")\n",
    "validation[\"dataset_iter\"] = val_data_provider.get_dataset(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Prepare training\")\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    ema_decay=ema_decay,\n",
    "    decay_patience=decay_patience,\n",
    "    decay_factor=decay_factor,\n",
    "    decay_cooldown=decay_cooldown,\n",
    "    grad_clip_max=grad_clip_max,\n",
    "    rho_force=rho_force,\n",
    "    mve=mve,\n",
    "    loss=loss,\n",
    "    staircase=staircase,\n",
    "    agc=agc,\n",
    ")\n",
    "\n",
    "# Initialize metrics\n",
    "train[\"metrics\"] = Metrics(\"train\", trainer.tracked_metrics)\n",
    "validation[\"metrics\"] = Metrics(\"val\", trainer.tracked_metrics)\n",
    "\n",
    "# Save/load best recorded loss (only the best model is saved)\n",
    "metrics_best = BestMetrics(best_dir, validation[\"metrics\"])\n",
    "\n",
    "# Set up checkpointing\n",
    "# Restore latest checkpoint\n",
    "if os.path.exists(log_path_model):\n",
    "    logging.info(\"Restoring model and trainer\")\n",
    "    model_checkpoint = torch.load(log_path_model)\n",
    "    model.load_state_dict(model_checkpoint[\"model\"])\n",
    "\n",
    "    train_checkpoint = torch.load(log_path_training)\n",
    "    trainer.load_state_dict(train_checkpoint[\"trainer\"])\n",
    "    # restore the best saved results\n",
    "    metrics_best.restore()\n",
    "    logging.info(f\"Restored best metrics: {metrics_best.loss}\")\n",
    "    step_init = int(train_checkpoint[\"step\"])\n",
    "else:\n",
    "    logging.info(\"Freshly initialize model\")\n",
    "    metrics_best.inititalize()\n",
    "    step_init = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(log_dir)\n",
    "steps_per_epoch = int(np.ceil(num_train / batch_size))\n",
    "\n",
    "for step in range(step_init + 1, num_steps + 1):\n",
    "\n",
    "    # keep track of the learning rate\n",
    "    if step % 10 == 0:\n",
    "        lr = trainer.schedulers[0].get_last_lr()[0]\n",
    "        summary_writer.add_scalar(\"lr\", lr, global_step=step)\n",
    "\n",
    "    # Perform training step\n",
    "    trainer.train_on_batch(train[\"dataset_iter\"], train[\"metrics\"])\n",
    "\n",
    "    # Save progress\n",
    "    if step % save_interval == 0:\n",
    "        torch.save({\"model\": model.state_dict()}, log_path_model)\n",
    "        torch.save(\n",
    "            {\"trainer\": trainer.state_dict(), \"step\": step}, log_path_training\n",
    "        )\n",
    "\n",
    "    # Check performance on the validation set\n",
    "    if step % evaluation_interval == 0:\n",
    "\n",
    "        # Save backup variables and load averaged variables\n",
    "        trainer.save_variable_backups()\n",
    "        trainer.load_averaged_variables()\n",
    "\n",
    "        # Compute averages\n",
    "        for i in range(int(np.ceil(num_val / batch_size))):\n",
    "            trainer.test_on_batch(validation[\"dataset_iter\"], validation[\"metrics\"])\n",
    "\n",
    "        # Update and save best result\n",
    "        if validation[\"metrics\"].loss < metrics_best.loss:\n",
    "            metrics_best.update(step, validation[\"metrics\"])\n",
    "            torch.save(model.state_dict(), best_path_model)\n",
    "\n",
    "        # write to summary writer\n",
    "        metrics_best.write(summary_writer, step)\n",
    "\n",
    "        epoch = step // steps_per_epoch\n",
    "        train_metrics_res = train[\"metrics\"].result(append_tag=False)\n",
    "        val_metrics_res = validation[\"metrics\"].result(append_tag=False)\n",
    "        metrics_strings = [\n",
    "            f\"{key}: train={train_metrics_res[key]:.6f}, val={val_metrics_res[key]:.6f}\"\n",
    "            for key in validation[\"metrics\"].keys\n",
    "        ]\n",
    "        logging.info(\n",
    "            f\"{step}/{num_steps} (epoch {epoch}): \" + \"; \".join(metrics_strings)\n",
    "        )\n",
    "\n",
    "        # decay learning rate on plateau\n",
    "        trainer.decay_maybe(validation[\"metrics\"].loss)\n",
    "\n",
    "        train[\"metrics\"].write(summary_writer, step)\n",
    "        validation[\"metrics\"].write(summary_writer, step)\n",
    "        train[\"metrics\"].reset_states()\n",
    "        validation[\"metrics\"].reset_states()\n",
    "\n",
    "        # Restore backup variables\n",
    "        trainer.restore_variable_backups()\n",
    "\n",
    "        # early stopping\n",
    "        if step - metrics_best.step > patience * evaluation_interval:\n",
    "            break\n",
    "\n",
    "result = {key + \"_best\": val for key, val in metrics_best.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in metrics_best.items():\n",
    "    print(f\"{key}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d62da17299be9defd8dbe3e03235aa2caefd9a4a0f498723db5c7f5e0b666b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
